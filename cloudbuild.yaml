substitutions:
  _REGION: us-central1
  _REPO: apexflow-api
  _IMAGE: ${_REGION}-docker.pkg.dev/${PROJECT_ID}/${_REPO}/api
  _SERVICE_ACCOUNT: apexflow-api@${PROJECT_ID}.iam.gserviceaccount.com
  _VPC_CONNECTOR: apexflow-vpc-connector
  _ALLOYDB_HOST: ''  # REQUIRED: set via trigger substitution or --substitutions
  _CI_DB_PASSWORD: 'ci-test-only'  # ephemeral CI container, not a real credential

steps:
  # Step 0: Validate required substitutions
  - name: 'bash'
    args:
      - '-c'
      - |
        if [ -z "${_ALLOYDB_HOST}" ] || echo "${_ALLOYDB_HOST}" | grep -q '^10\.x'; then
          echo "ERROR: _ALLOYDB_HOST must be set to a real AlloyDB private IP via trigger substitutions."
          exit 1
        fi
    id: 'validate-config'
    waitFor: ['-']

  # Step 1: Start pgvector container on the cloudbuild network
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'run'
      - '-d'
      - '--name=postgres'
      - '--network=cloudbuild'
      - '-e'
      - 'POSTGRES_USER=apexflow'
      - '-e'
      - 'POSTGRES_PASSWORD=${_CI_DB_PASSWORD}'
      - '-e'
      - 'POSTGRES_DB=apexflow'
      - 'pgvector/pgvector:pg15'
    id: 'start-db'

  # Step 2: Wait for PostgreSQL to be ready
  - name: 'ghcr.io/astral-sh/uv:python3.12-bookworm-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        uv pip install --system psycopg2-binary
        for i in $(seq 1 30); do
          python -c "
        import psycopg2
        try:
            conn = psycopg2.connect(host='postgres', user='apexflow', password='${_CI_DB_PASSWORD}', dbname='apexflow')
            conn.close()
            exit(0)
        except:
            exit(1)
        " && break || sleep 2
        done
    id: 'wait-for-db'
    waitFor: ['start-db']

  # Step 3: Lint with ruff (uvx runs ruff without installing into the project)
  - name: 'ghcr.io/astral-sh/uv:python3.12-bookworm-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        uvx ruff check .
    id: 'lint'
    waitFor: ['-']

  # Step 4: Type check with mypy
  - name: 'ghcr.io/astral-sh/uv:python3.12-bookworm-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        uv sync --extra dev
        uv run mypy core/
    id: 'typecheck'
    waitFor: ['-']

  # Step 5: Run Alembic migrations
  - name: 'ghcr.io/astral-sh/uv:python3.12-bookworm-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        uv sync --extra dev
        export DB_HOST=postgres
        export DB_PASSWORD=${_CI_DB_PASSWORD}
        uv run alembic upgrade head
    id: 'migrate'
    waitFor: ['wait-for-db']

  # Step 6: Run tests
  - name: 'ghcr.io/astral-sh/uv:python3.12-bookworm-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        uv sync --extra dev
        export DB_HOST=postgres
        export DB_PASSWORD=${_CI_DB_PASSWORD}
        uv run pytest tests/ -v
    id: 'test'
    waitFor: ['migrate']

  # Step 7: Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - '${_IMAGE}:${SHORT_SHA}'
      - '-t'
      - '${_IMAGE}:latest'
      - '.'
    id: 'docker-build'
    waitFor: ['test']

  # Step 8: Push Docker image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - '${_IMAGE}'
    id: 'docker-push'
    waitFor: ['docker-build']

  # Step 9: Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'apexflow-api'
      - '--image=${_IMAGE}:${SHORT_SHA}'
      - '--region=${_REGION}'
      - '--platform=managed'
      - '--allow-unauthenticated'
      - '--service-account=${_SERVICE_ACCOUNT}'
      - '--vpc-connector=${_VPC_CONNECTOR}'
      - '--vpc-egress=private-ranges-only'
      - '--set-secrets=ALLOYDB_PASSWORD=apexflow-db-password:latest,GEMINI_API_KEY=gemini-api-key:latest'
      - '--set-env-vars=ALLOYDB_HOST=${_ALLOYDB_HOST},ALLOYDB_DB=apexflow,ALLOYDB_USER=apexflow,LOG_LEVEL=INFO,CORS_ORIGINS=https://apexflow.web.app'
      - '--memory=1Gi'
      - '--cpu=1'
      - '--concurrency=80'
      - '--max-instances=10'
      - '--timeout=300'
    id: 'deploy'
    waitFor: ['docker-push', 'validate-config']

images:
  - '${_IMAGE}:${SHORT_SHA}'
  - '${_IMAGE}:latest'

options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY
